{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","# keras and dependencies\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import ResNet50\n","from keras.applications.resnet50 import preprocess_input\n","from keras import Model, layers\n","from keras.models import load_model, model_from_json\n","import os\n","# Undesiderable fix of a bug. But so far it's the only way.\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'models/keras/architecture.json'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f85fa86e97da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# architecture from JSON, weights from HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/keras/architecture.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/keras/weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/keras/architecture.json'"]}],"source":["# architecture from JSON, weights from HDF5\n","with open('models/keras/architecture.json') as f:\n","    model = model_from_json(f.read())\n","model.load_weights('models/keras/weights.h5')\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# imgs to test\n","validation_img_paths = [\"data/validation/alien/11.jpg\",\n","                        \"data/validation/alien/22.jpg\",\n","                        \"data/validation/predator/33.jpg\"]\n","img_list = [Image.open(img_path) for img_path in validation_img_paths]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# perfrom test\n","img_size = 250\n","validation_batch = np.stack([preprocess_input(np.array(img.resize((img_size, img_size))))\n","                             for img in img_list])\n","\n","pred_probs = model.predict(validation_batch)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, axs = plt.subplots(1, len(img_list), figsize=(20, 5))\n","for i, img in enumerate(img_list):\n","    ax = axs[i]\n","    ax.axis('off')\n","    ax.set_title(\"{:.0f}% Alien, {:.0f}% Predator\".format(100*pred_probs[i,0],\n","                                                          100*pred_probs[i,1]))\n","    ax.imshow(img)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}